{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeef269-510b-4558-a099-200d94be72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "pip install -r\n",
    "pip install langchain langchain-text-splitters langchain-community bs4\n",
    "pip install -U \"langchain-openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd38b5-cb95-4b21-afb2-37111122efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les dependencies\n",
    "import os\n",
    "from google import genai\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245e02f-3dd9-4704-9206-64f5933e162d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:20:20.213376Z",
     "iopub.status.busy": "2025-11-03T20:20:20.212435Z",
     "iopub.status.idle": "2025-11-03T20:20:20.223977Z",
     "shell.execute_reply": "2025-11-03T20:20:20.221731Z",
     "shell.execute_reply.started": "2025-11-03T20:20:20.213338Z"
    }
   },
   "source": [
    "**Création de la clé API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b94d98-0efb-4e7c-bf61-36fac9dad369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Gemini API key\n",
    "export GOOGLE_API_KEY=\n",
    "os.environ['GOOGLE_API_KEY'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ece795-50bc-4861-b2b5-3226e50ea492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T21:16:54.673033Z",
     "iopub.status.busy": "2025-11-03T21:16:54.672037Z",
     "iopub.status.idle": "2025-11-03T21:16:54.681318Z",
     "shell.execute_reply": "2025-11-03T21:16:54.679629Z",
     "shell.execute_reply.started": "2025-11-03T21:16:54.672976Z"
    }
   },
   "source": [
    "***1.Solution 1 - Le builtin de Gemini***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9f3e8-f739-40f9-9615-1ba93472e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-mini\")\n",
    "\n",
    "tool = {\"type\": \"web_search\"}\n",
    "model_with_tools = model.bind_tools([tool])\n",
    "\n",
    "response = model_with_tools.invoke(\"What was a positive news story from today?\")\n",
    "response.content_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5c262-5353-4b41-855b-b6f48b838e2a",
   "metadata": {},
   "source": [
    "***2. Solution 2 - Construction pas à pas***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fffb5-98cd-4342-8452-41f50fc3e600",
   "metadata": {},
   "source": [
    "***Create an Agent***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2787ff-24c9-4e7c-a1f4-cd204717caf2",
   "metadata": {},
   "source": [
    "The easiest way to get started with a standalone model in LangChain is to use init_chat_model to initialize one from a chat model provider of your choice (examples below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dae69bc-a167-4b40-b30c-7ef3c783745f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:37:16.459096Z",
     "iopub.status.busy": "2025-11-03T20:37:16.458198Z",
     "iopub.status.idle": "2025-11-03T20:37:16.747560Z",
     "shell.execute_reply": "2025-11-03T20:37:16.746194Z",
     "shell.execute_reply.started": "2025-11-03T20:37:16.459054Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate a Gemini client\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Choose a tool\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tools\u001b[38;5;241m=\u001b[39mgenai\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mTool(function_declarations\u001b[38;5;241m=\u001b[39m[get_matches_declaration])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genai' is not defined"
     ]
    }
   ],
   "source": [
    "#initialize the model\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "\n",
    "#create an agent\n",
    "agent = create_agent(\n",
    "    \"2.5-flash-lite\",\n",
    "    tools=tools\n",
    "    checkpointer=InMemorySaver(), \n",
    ")\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a18a9-351e-480d-9952-9042c07c01b5",
   "metadata": {},
   "source": [
    "***Initialize a model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf0e861-bd10-43d9-a059-0b9ee1976f22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T21:16:06.906836Z",
     "iopub.status.busy": "2025-11-03T21:16:06.905654Z",
     "iopub.status.idle": "2025-11-03T21:16:06.942459Z",
     "shell.execute_reply": "2025-11-03T21:16:06.940281Z",
     "shell.execute_reply.started": "2025-11-03T21:16:06.906800Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Choose a tool\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tools\u001b[38;5;241m=\u001b[39m\u001b[43mgenai\u001b[49m\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mTool(function_declarations\u001b[38;5;241m=\u001b[39m[get_matches_declaration])\n\u001b[1;32m      3\u001b[0m tool \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      4\u001b[0m model_with_tools \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbind_tools([tool])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genai' is not defined"
     ]
    }
   ],
   "source": [
    "client = genai.Client()\n",
    "# Choose a tool\n",
    "tools=genai.types.Tool(function_declarations=[get_matches_declaration])\n",
    "tool = {\"type\": \"web_search\"}\n",
    "model_with_tools = model.bind_tools([tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb2c88-4cbf-46b9-9f5a-c917c3011d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T21:06:50.630758Z",
     "iopub.status.busy": "2025-11-03T21:06:50.629890Z",
     "iopub.status.idle": "2025-11-03T21:06:50.641330Z",
     "shell.execute_reply": "2025-11-03T21:06:50.639006Z",
     "shell.execute_reply.started": "2025-11-03T21:06:50.630691Z"
    }
   },
   "source": [
    "***Tools***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b00ff5-057e-49ea-bfab-074cf83fafd0",
   "metadata": {},
   "source": [
    "Many AI applications interact with users via natural language. However, some use cases require models to interface directly with external systems—such as APIs, databases, or file systems—using structured input.\n",
    "Tools are components that agents call to perform actions. They extend model capabilities by letting them interact with the world through well-defined inputs and outputs. Tools encapsulate a callable function and its input schema. These can be passed to compatible chat models, allowing the model to decide whether to invoke a tool and with what arguments. In these scenarios, tool calling enables models to generate requests that conform to a specified input schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea5765-269d-4eee-860b-36f2a9862549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step is to describe the function so the LLM understands what it does.\n",
    "get_matches_declaration = {\n",
    "    \"name\": \"get_matches\",\n",
    "    \"description\": \"Return the rows in a DataFrame about men's football games which satisfy the criteria\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"nationality_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the player's country \",\n",
    "            },\n",
    "            \"club_contract_valid_until_year\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"When the player is up to be bought\",\n",
    "            },\n",
    "            \"club_position\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The field position\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"nationality_name\", \"club_contract_valid_until_year\", \"club_position\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afed2c9-b78c-417a-a9d2-ff50761c56f1",
   "metadata": {},
   "source": [
    "Then, we can feed the function declaration together with the user's query to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8cb2f-b4b8-43d2-8c75-9434997ba206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the declaration into a `Tool`\n",
    "tools = genai.types.Tool(\n",
    "    function_declarations=[\n",
    "        get_matches_declaration\n",
    "    ]\n",
    ")\n",
    "\n",
    "user_question = \"\"\"Tell me more about the player, his availability\"\"\"\n",
    "\n",
    "# Use the model\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=user_question,  # The question\n",
    "    config=genai.types.GenerateContentConfig(\n",
    "        tools=[tools]        # The tool\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912fbd0-2a4b-484b-a293-803fb9816e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative : deuxième fichier fastapi créer l'appel à la fonction\n",
    "@tool(\"web_search\")  # Custom name\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "print(search.name)  # web_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df66a86e-f73c-4efb-a99b-0fd4c86a4a66",
   "metadata": {},
   "source": [
    "***Create a message***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867f088-2336-4c55-a6dd-3dca8bcec217",
   "metadata": {},
   "source": [
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM.\n",
    "Messages are objects that contain:\n",
    " Role - Identifies the message type (e.g. system, user)\n",
    " Content - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    " Metadata - Optional fields such as response information, message IDs, and token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d80eb6-e068-41a5-acbe-5b12a825502c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:39:52.396477Z",
     "iopub.status.busy": "2025-11-03T20:39:52.395323Z",
     "iopub.status.idle": "2025-11-03T20:39:52.429111Z",
     "shell.execute_reply": "2025-11-03T20:39:52.426812Z",
     "shell.execute_reply.started": "2025-11-03T20:39:52.396442Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Générer une réponse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.0-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     contents\u001b[38;5;241m=\u001b[39muser_question,\n\u001b[1;32m      5\u001b[0m     config\u001b[38;5;241m=\u001b[39mgenai\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mgenerateContentConfig(tools\u001b[38;5;241m=\u001b[39m[tools]),)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Générer une réponse\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=user_question,\n",
    "    config=genai.types.generateContentConfig(tools=[tools]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce44d1e-d2a3-475b-80ce-e5f9b37e932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The LLM has extracted the arguments that we can use for our function:\n",
    "args = response.candidates[0].content.parts[0].function_call.args\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78192bc6-99fc-4a2c-9d41-4c97a28f57b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T21:05:02.423994Z",
     "iopub.status.busy": "2025-11-03T21:05:02.423048Z",
     "iopub.status.idle": "2025-11-03T21:05:02.484161Z",
     "shell.execute_reply": "2025-11-03T21:05:02.482488Z",
     "shell.execute_reply.started": "2025-11-03T21:05:02.423946Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SystemMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m system_msg \u001b[38;5;241m=\u001b[39m \u001b[43mSystemMessage\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m human_msg \u001b[38;5;241m=\u001b[39m HumanMessage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, how are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Use with chat models\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SystemMessage' is not defined"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You are a Football expert\")\n",
    "human_msg = HumanMessage(\"Hello, how are you? Want to talk about outstanding players ?\")\n",
    "\n",
    "# Use with chat models\n",
    "messages = [system_msg, human_msg]\n",
    "response = model.invoke(messages)  # Returns AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030a413-c8ac-4bdd-bcf0-8e7d29c179a2",
   "metadata": {},
   "source": [
    "***/***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08e59a-7fbb-4ffc-a325-3c1bd899a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
